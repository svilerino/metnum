% TODO

% Deben  explicarse  los  metodos  numericos  que  utilizaron  y  su  aplicacion  al  problema
% concreto  involucrado  en  el  trabajo  practico.   Se  deben  mencionar  los  pasos  que  si-
% guieron para implementar los algoritmos, las dicultades que fueron encontrando y la
% descripcion de como las fueron resolviendo.  Explicar tambien como fueron planteadas
% y realizadas las mediciones experimentales.  Los ensayos fallidos, hipotesis y conjeturas
% equivocadas,  experimentos  y  metodos  malogrados  deben  gurar  en  esta  seccion,  con
% una breve explicacion de los motivos de estas fallas (en caso de ser conocidas).

\subsection{Armado del sistema de ecuaciones}
De la discretización de la ecuación del calor provista por el informe resulta una nueva ecuación que nos va a servir para armar nuestro sistema discreto.

\begin{equation}\label{calor}
\frac{t_{j-1,k}-2t_{jk}+t_{j+1,k}}{(\Delta r)^2}+\frac{1}{r_j}\frac{t_{j,k}-t_{j-1,k}}{\Delta r}+\frac{1}{{r_j}^2}\frac{t_{j,k-1}-2t_{jk}+t_{j,k+1}}{(\Delta \theta)^2} = 0 
\end{equation}

Esta ecuación vale para cada punto $(r_j, \theta_k)$ del modelo salvo los límites, sobre los cuales hablaremos en breve.

Para poder armar el sistema $Ax=b$ equivalente, es necesario:
\begin{itemize}
 \item
    Extraer los factores que multiplican a cada una de las cinco incógnitas: $t_{j-1,k}$; $t_{j,k}$; $t_{j+1,k}$; $t_{j,k-1}$ y $t_{j,k+1}$.

    Estos se obtienen de la ecuación \ref{calor}.
    \begin{align*}
        t_{j-1, k}&*(\frac{1}{(\Delta r)^2} - \frac{1}{r_j \Delta r}) \\
        t_{j, k}  &*(\frac{-2}{(\Delta r)^2} + \frac{1}{r_j \Delta r} - \frac{2}{{r_j}^2 (\Delta \theta)^2}) \\
        t_{j+1, k}&*(\frac{1}{(\Delta r)^2}) \\
        t_{j, k-1}&*(\frac{1}{{r_j}^2(\Delta \theta)^2}) \\
        t_{j, k+1}&*(\frac{1}{{r_j}^2(\Delta \theta)^2})
    \end{align*}
    Por cuestiones de espacio, en adelante llamaremos $M_{j,k}$ al factor que multiplica a la incógnita $t_{j,k}$, $M_{j-1,k}$ al que multiplica a $t_{j-1,k}$ y así sucesivamente. Y resumiremos $Mt_{j,k} = M_{j,k}*t_{j,k}$, $Mt_{j-1,k}=M_{j-1,k}*t_{j-1,k}$, etc.
 \item
    Analizar los ``casos borde'': aquellos puntos donde la ecuación \ref{calor} no vale.
    
    Para evitar confusiones de variables, tomaremos $\theta_0 = 0$ como el menor valor posible de $\theta$ y $\theta_{n-1}$ como el mayor, pues vale $(r_j, \theta_n) = (r_j, \theta_0)$ para cualquier $j$. 
    
    Los casos interesantes para valores de $j, k$ entonces son:
    \begin{enumerate}
     \item La pared interior del horno ($j = 0$; $k = 0, ..., n-1$). La ecuación en esos casos es $t_{0, k} = T_i(\theta_k)$.
     \item La pared exterior del horno ($j = m$; $k = 0, ..., n-1$). La ecuación en esos casos es $t_{m, k} = T_e(\theta_k)$.
     \item El valor mínimo de $\theta$ ($j = 0, ..., m$; $k = 0$). Se debe reemplazar $t_{j, k-1}$ por $t_{j, n-1}$ en todas las ecuaciones correspondientes.
     \item El valor máximo de $\theta$ ($j = 0, ..., m$; $k = n-1$). Se debe reemplazar $t_{j, k+1}$ por $t_{j, 0}$ en todas las ecuaciones correspondientes.
    \end{enumerate}
    Estos últimos reemplazos se pueden resumir en $$(j, k) \Rightarrow (j, k \text{ mod } n)$$
 \item
    Combinar los puntos anteriores para plantear el sistema de ecuaciones a resolver:
    \begin{align*}\label{sistema}
    &t_{0, k} = T_i(\theta_k)                                           &\forall k = 0, ..., n-1  \\
    &t_{m, k} = T_e(\theta_k)                                           &\forall k = 0, ..., n-1  \\
    &Mt_{j-1,k} + Mt_{j,k} + Mt_{j+1,k} + Mt_{j,k-1} + Mt_{j,k+1} = 0  &\forall j=1, ..., m-1; k = 1, ... , n-2 \\
    &Mt_{j-1,0} + Mt_{j,0} + Mt_{j+1,0} + Mt_{j,n-1} + Mt_{j,1} = 0    &\forall j=1, ..., m-1 \\
    &Mt_{j-1,n-1} + Mt_{j,n-1} + Mt_{j+1,n-1} + Mt_{j,n-2} + Mt_{j,0} = 0    &\forall j=1, ..., m-1
    \end{align*}

    Del mismo podemos obtener la matriz $A$ (que tendrá 5 valores no nulos por fila a lo sumo) y el vector $b$ (que será nulo en todas sus componentes salvo aquellas correspondientes a $j=0$ y $j=m$).
  \item
    Pensar un orden para las incógnitas que permita asegurar que la matriz resultante sea $banda$. El mismo es:
    
    $$ (0,0); (0,1); ... ; (0,n-1); (1,0); (1,1); ... ; (j,n-1); (j+1,0); (j,1); ... ; (m, n-1)$$ % TODO: estaría bueno hacer una imagen representativa, que muestre un toque la espiral rara esta. No sé usar mucho ninguna herramienta como para hacerlo :(.
    
    tanto para las filas como para las columnas. Este orden garantiza que la distancia máxima de un punto hasta sus vecinos en la matriz es de $n$ posiciones (para los casos $j+1, k$ y $j-1, k$) y por lo tanto el ``ancho'' de la banda es de $2n$.
    
    Notar que las filas que coinciden con la identidad no afectan esta propiedad, dado que son ``banda'' de ancho $1$.
\end{itemize}

Una vez realizados estos pasos estamos en condiciones de plantear el sistema de ecuaciones $Ax=b$:

Lo primero que debemos notar es que como hay $n*(m+1)$ puntos diferentes tendremos $n*(m+1)$ incógnitas diferentes. Luego, $A \in \mathbb{R}^{n(m+1)*n(m+1)}$: cada columna y cada fila de $A$ corresponden a un punto $P_{j,k}$ del sistema. Asimismo, $x \in \mathbb{R}^{n(m+1)}$ y $b \in \mathbb{R}^{n(m+1)}$. 

Lo segundo que debemos notar es que, por coincidir el orden elegido para filas y para columnas, el índice de la fila correspondiente al punto $P_{j,k}$ coincide con el de la columna correspondiente a ese punto. Llamaremos a este índice $i(j,k)$. Notar que podemos computar $i$ fácilmente como $i(j,k)=j*n+k$ (suponiendo que indexamos por 0 tanto filas como columnas).

Por el orden elegido, las primeras $n$ filas corresponden a los puntos $P_{0,k}$ con $k=0,...,n-1$. Mirando el sistema de ecuaciones, las primeras $n$ filas de $A$ coinciden con la identidad (1 en la diagonal y 0 en el resto) y las primeras $n$ filas de $b$ coinciden con $T_i(\theta_k)$.

Lo mismo vale para las últimas $n$ filas: corresponden a los puntos $P_{m,k}$ con $k=0,...,n-1$, las filas correspondientes de $A$ coinciden con la identidad y las componentes de $b$ con $T_e(\theta_k)$.

Llegado este punto podemos definir completamente $b$: todas sus demás componentes son nulas (por ser $0$ la solución al resto de las ecuaciones del sistema), por lo que resulta:

$$b = (T_i(0), T_i(1), ..., T_i(n-1), 0, ..., 0, T_e(0), T_e(1), ..., T_e(n-1)) $$

Para $j \not = 0, j \not = m$, las filas $i(j,k)$ de $A$ tendrán cinco componentes no-nulas (que corresponden a los vecinos de $P_{j,k}$ en el modelo). Fijados $j$ y $k$ ($0\not=j\not=m, 0\not=k\not=n-1$), estas componentes serán $i(j-1,k); i(j,k); i(j+1,k); i(j,k-1)$ e $i(j,k+1)$ y coincidirán con lo que anteriormente llamamos $M(j-1,k); M(j,k); M(j+1,k); M(j,k-1)$ y $M(j,k+1)$ respectivamente. 

Resta simplemente considerar los casos $k=0$ y $k=n-1$, pero no reviste mayor complejidad que tomar módulo $n$ después de las operaciones que involucren $k$.

\subsection{Resolución del sistema de ecuaciones}
\subsubsection{Caracterización de la matriz}

\begin{proposition}

La matriz $A$ es banda y diagonal dominante (no estricta) por filas.

\begin{proof}

El hecho de que es banda fue fundamentado al momento de construirla.

Resta ver que es diagonal dominante (no estricta) por filas, es decir, que $$|a_{i, i}| \geq \sum\limits_{j \neq i}^{n*(m+1)} |a_{i, j}| \hspace{10pt} \forall i = 1, ..., n*(m+1)$$

Las primeras y últimas $n$ filas de $A$ coinciden con la identidad, por lo que esto vale trivialmente. Dada cualquier otra fila $i(j, k)$ con $j \neq 0, j \neq m$ debemos recordar que hay solo 5 valores no nulos, por lo que en realidad queremos probar $$|M_{j, k}| \geq |M_{j-1, k}| + |M_{j+1, k}| + |M_{j, k-1}| + |M_{j, k+1}|$$

Reemplazando por los valores de los multiplicadores, se obtiene

$$\left|\frac{-2}{(\Delta r)^2} + \frac{1}{r_j \Delta r} - \frac{2}{{r_j}^2 (\Delta \theta)^2}\right| \geq \left|\frac{1}{(\Delta r)^2} - \frac{1}{r_j \Delta r}\right| + \left|\frac{1}{(\Delta r)^2}\right| + 2 * \left|\frac{1}{{r_j}^2(\Delta \theta)^2}\right| $$

Quitando el módulo en los valores claramente positivos y reordenando, tenemos

$$\left|\frac{1}{r_j \Delta r} - \frac{2}{(\Delta r)^2} - \frac{2}{{r_j}^2 (\Delta \theta)^2}\right| \geq \left|\frac{1}{(\Delta r)^2} - \frac{1}{r_j \Delta r}\right| + \frac{1}{(\Delta r)^2} + \frac{2}{{r_j}^2(\Delta \theta)^2} $$

En este punto nos detuvimos a analizar cada caso en particular, pero pronto descubrimos que solo vale la pena uno:
como sabemos $j \neq 0$, entonces $r_j \geq \Delta r$ para cualquier valor de $j$, pues hasta el primer radio distinto al interior hay por lo menos un incremento en la discretización. Por lo tanto 
$$\frac{1}{r_j \Delta r} \leq \frac{1}{(\Delta r)^2}$$
$$0 \leq \frac{1}{(\Delta r)^2} - \frac{1}{r_j \Delta r}$$

Por lo que podemos omitir el módulo de la derecha. Asimismo, 
$$ \frac{1}{r_j \Delta r} \leq \frac{1}{(\Delta r)^2} $$
$$ \frac{1}{r_j \Delta r} < \frac{2}{(\Delta r)^2} $$
$$ \frac{1}{r_j \Delta r} - \frac{2}{(\Delta r)^2} < 0 $$

Y por ser $\frac{2}{{r_j}^2 (\Delta \theta)^2} > 0$ podemos afirmar
$$ \frac{1}{r_j \Delta r} - \frac{2}{(\Delta r)^2} - \frac{2}{{r_j}^2 (\Delta \theta)^2} < 0 $$

Por lo que podemos deshacernos del módulo de la izquierda negando sus términos. 
$$\frac{2}{(\Delta r)^2} - \frac{1}{r_j \Delta r} + \frac{2}{{r_j}^2 (\Delta \theta)^2} \geq \frac{1}{(\Delta r)^2} - \frac{1}{r_j \Delta r} + \frac{1}{(\Delta r)^2} + \frac{2}{{r_j}^2(\Delta \theta)^2} $$

$$\frac{2}{(\Delta r)^2} - \frac{1}{r_j \Delta r} + \frac{2}{{r_j}^2 (\Delta \theta)^2} \geq \frac{2}{(\Delta r)^2} - \frac{1}{r_j \Delta r} + \frac{2}{{r_j}^2(\Delta \theta)^2} $$

Con lo cual la desigualdad es trivialmente cierta (y de hecho resulta ser una igualdad, lo cual explica por qué no es ``estrictamente'' diagonal dominante).
\end{proof}
\end{proposition}
\subsubsection{Resolución sin pivoteo}
Nos interesa demostrar que es posible aplicar Eliminación Gaussiana sin pivoteo en la matriz $A$.


Para su demostración usaremos la propiedad vista en clase teórica de que aplicar un paso de la Eliminación Gaussiana sobre una matriz estrictamente diagonal dominante preserva esa propiedad en la matriz resultante, y el siguiente lema
\begin{lemma}\label{izquierda}
 Toda fila $i(j,k)$ de la matriz $A$ tiene un elemento no nulo a la izquierda de la diagonal, salvo aquellas que coinciden con la identidad ($j=0$ y $j=m$).
\end{lemma}
\begin{proof}
Surge directamente de analizar el orden elegido para los puntos: como $j \neq 0$ todo punto $P_{j, k}$ tiene un vecino $P_{j-1,k}$ que necesariamente está antes en el orden elegido.
\end{proof}

Podemos probar entonces que si bien nuestra matriz no es \emph{estrictamente} diagonal dominante por filas sí lo serán las filas con las que trabaje la Eliminación Gaussiana.

\begin{proposition}\label{pivoteo}
 A cada paso $k$ de la Eliminación Gaussiana (empezando por 0), la fila $k$ con la que trabaje será estrictamente diagonal dominante (y por lo tanto no tendrá un 0 en el elemento de la diagonal y podrá operar normalmente).
\end{proposition}
\begin{proof}
 Inducción global en $k$.
 
 El caso $k < n$ es trivial, dado que las filas coinciden con la identidad (y por lo tanto son estrictamente diagonal dominantes).
 
 Para el caso $k = n$, vale el lema \ref{izquierda} que nos dice que la fila $k$ tenía un elemento no nulo a la izquierda de la diagonal en la matriz $A$. Pero para el paso $k$, las $k$ primeras columnas fueron anuladas, es decir $A_{k,j}^{(k)}=0$ $\forall j < k$. Y como por encima de $A_{k,k}$ solo había 0, la fila ahora es diagonal dominante estricta.
 
\end{proof}

\subsection{Experimentos y mediciones}
En esta seccion desarrollaremos acerca de los experimentos planteados, desde la generacion de instancias de prueba hasta los criterios de medicion utilizados y los experimentos planteados.
\subsubsection{Consideraciones iniciales}
\begin{itemize}
    \item La pared interna del horno en teoria deberia ser de 1500 grados constantes, nosotros consideramos mas realista que al variar los angulos de la pared interna, la temperatura varie uniformemente entre 1450 y 1550.
\end{itemize}

\subsubsection{Generacion de casos de prueba}
\textcolor{red}{Mati, let the game begin, explica tu testgen}

\subsubsection{Metricas de performance}
\textcolor{red}{Demo teorica o empirica de que como $dim = n*(m+1)$ entonces los algoritmos son $\mathcal{O}(n^k.m^k)$ con k variando segun el grado polinomial de la complejidad del algoritmo.}

\subsubsection{Metodo de posicionamiento estimado de la isoterma}
El problema consiste en estimar, para cada angulo, la posicion radial de la isoterma \texttt{$\alpha$}.\\
Consideremos la funcion de temperatura $T(r,\theta)$. Si fijamos $\theta = \theta_i$ podemos definir la funcion $g_{\theta_i}(r) = T(r,\theta_i)$ como la funcion de temperatura sobre todos los radios del angulo $\theta_i$. Dado que nosotros conocemos $m+1$ puntos aproximados de dicha funcion, esto reduce el problema a aproximar el elemento $ z_\alpha \in Dom(g_{\theta_i}) $ tal que $g_{\theta_i}(z_\alpha) = \alpha$. El metodo propuesto consiste en aplicar el siguiente algoritmo a las aproximaciones discretas conocidas de las funciones $g_{\theta_i}$, para todos los angulos.
\begin{theorem}[Metodo de estimacion de la isoterma k]
    Sea $\hat{g_{\theta_i}}$ la funcion \textbf{discreta de aproximaciones} de temperatura de un angulo i.
    \begin{enumerate}
        \item Buscar $ x_1, x_2 \in Dom(\hat{g_{\theta_i}}) $ tales que $ \hat{g_{\theta_i}}(x_1) \leq \alpha \leq \hat{g_{\theta_i}}(x_2)$ y esta cota sea ajustada.
        
        \item $z_\alpha = x_1 + \left(\frac{x_2 - x_1}{\hat{g_{\theta_i}}(x_2) - \hat{g_{\theta_i}}(x_1)}\right) * (\alpha - \hat{g_{\theta_i}}(x_1))$

        \item Devolver $z_\alpha$.
    \end{enumerate}
    $z_\alpha$ es la posicion estimada de la isoterma tal que $g_{\theta_i}(z_\alpha) = \alpha$.
\end{theorem}

\begin{proposition}[Dominio de correctitud de la estimacion]
    El algoritmo anterior estima linealmente la isoterma $\alpha$ entre $x_1$ y $x_2$ si:
    \begin{itemize}
        \item $\displaystyle\min_{x \in Dom(\hat{g_{\theta_i}})}{\hat{g_{\theta_i}}(x)} \leq \alpha \leq \displaystyle\max_{x \in Dom(\hat{g_{\theta_i}})}{\hat{g_{\theta_i}}(x)}$.
        \item $\alpha \notin Im(\hat{g_{\theta_i}})$.
    \end{itemize}
    \begin{itemize}
        \item En caso de que $\alpha$ este fuera del rango $[min..max]$ por convencion se establece que la isoterma se encuentra en una posicion radial $R_i - \epsilon$ o $R_e + \epsilon$ segun corresponda.
        \item En caso de que $\alpha \in Im(\hat{g_{\theta_i}})$ entonces $z = x_1 = x_2$ y no es necesario ajuste lineal.
    \end{itemize}
\end{proposition}
\begin{proof}
    Si se cumplen las hipotesis de la proposicion anterior. Entonces la cota existe y el algoritmo  procedera a hacer el calculo aproximado del paso siguiente, que no es mas que un ajuste lineal entre los dos puntos de las cotas. Es decir, estamos asumiendo que el calor se disipa linealmente entre 2 puntos cualesquiera de la funcion.\\
    \vspace{0.3cm}
    \textbf{Nota:} Asumir esto no es necesariamente correcto, se podria hacer un analisis mas fino graficando las funciones $g_{\theta_i}$ y aplicando metodos mas avanzados de estimacion para que la curva quede mas suave. Por simplicidad solo consideramos el ajuste lineal en este trabajo.
\end{proof}

\subsubsection{Metricas de seguridad de la isoterma}
Plantemos una metrica que estima la \texttt{estabilidad} o \texttt{seguridad} de la pared del horno estableciendo una relacion relativa entre la posicion de la isoterma y el radio externo. 
\begin{proposition}[Metrica de seguridad del horno basada en la posicion relativa de la isoterma]
    Consideremos $\Delta_{iso_\alpha} = \left( \frac{f(iso_\alpha) - R_i}{R_e - R_i} \right)$.\\
    Donde $f(iso_\alpha)$ es una funcion de la isoterma, en nuestro caso, consideramos que el maximo o el promedio son buenas metricas.\\
    Salvo casos patologicos, vale que $0 \leq \Delta_{iso_\alpha}\leq 1$. Luego basta establecer un \textbf{limite de seguridad} $0 \leq \gamma_0 \leq 1$ tal que si vale $\Delta_{iso_\alpha} > \gamma_0$ se considera \texttt{inestable} o \texttt{insegura} la pared del horno.
\end{proposition}


\subsubsection{Evolucion de la temperatura y posicion de la isoterma con distintas discretizaciones}
Para evaluar la calidad de nuestros estimadores. Planteamos el siguiente experimento:
\begin{itemize}
    \item Se plantean los radios internos, externos y la isoterma buscada y se mantienen fijos durante todo el experimento.
    \item Se plantean un conjunto de temperaturas internas y externas iniciales y se mantienen fijas durante todo el experimento.
    \item Se plantea un numero de angulos de la discretizacion y se mantiene fijo durante todo el experimento. (Tengamos en cuenta que variar este parametro no nos permite sostener el item anterior y que lo unico que varia con este parametro es la cantidad de funciones a ajustar.) 
    \item Se plantea un rango $[r_{min}, r_{max}]$ que denota la cobertura de discretizaciones distintas del experimento.
    \item Se generan archivos de entrada $test_i$ variando unicamente la cantidad de radios de la discretizacion a utilizar con una instancia por archivo.
    \item Se ejecutan todos los archivos de entrada con el metodo de resolucion mas conveniente.
    \item Se grafica, para cada archivo de test, la posicion de la isoterma y el mapa de temperaturas del horno.
    \item Se considera un video que tiene por frames los graficos ordenados en el rango $[r{min}..r_{max}]$ del item anterior relacionado con la posicion de la isoterma.
    \item Se considera un video que tiene por frames los graficos ordenados en el rango $[r{min}..r_{max}]$ del item anterior relacionado con la temperatura de la pared del horno.
    \item Se grafica una funcion en el plano que denota la \textbf{maxima} posicion relativa de la isoterma en la pared del horno a medida que varia ordenadamente el rango $[r{min}..r_{max}]$.
    \item Se grafica una funcion en el plano que denota la posicion relativa \textbf{promedio} de la isoterma en la pared del horno a medida que varia ordenadamente el rango $[r{min}..r_{max}]$.
\end{itemize}

Se espera poder obtener conclusiones acerca de la suavidad de la curva estimada de la isoterma a medida que disminuye la granularidad de la discretizacion(aumenta la cantidad de radios). Asimismo en las funciones que grafican el maximo y el promedio, se espera poder obtener conclusiones similares respecto a la variacion radial de la curva polar de la isoterma.\\
\vspace{0.3cm}
\textbf{Se consideraron 2 experimentos de este tipo con diferente la cantidad de angulos y temperaturas aleatorias distintas entre los experimentos.}


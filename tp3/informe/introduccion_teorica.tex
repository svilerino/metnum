%!TEX root = informe.tex
\IEEEPARstart{E}{N} el siguiente trabajo se aborda el desafío de aumentar algorítmicamente la cantidad de frames de un video de manera que el resultado se asemeje al video original. En otras palabras, el objetivo es, a partir de un video, generar otro con mayor cantidad de frames, de modo tal que coincidan en aquellos frames presentes en el video original y los frames generados se \emph{ajusten} a estos, apuntando idealmente a que el ojo humano no perciba el agregado artificial.

En esta introducción presentaremos una lista no exhaustiva de las diversas situaciones que motivan la resolución de dicho problema y daremos un marco teórico a los métodos propuestos para su solución.

\subsection{La motivación}
\subsubsection{Compresión de video}
El aumento exponencial de internet ha dado lugar, entre otras cosas\cite{TP2}, a la mejora de la infraestructura utilizada, lo que en particular repercutió en un aumento generalizado de las velocidades de conexión y del ancho de banda de las mismas. Esto promovió su utilización para compartir contenido cada vez más pesado, en particular videos de todo tipo, desde caseros a profesionales. Además, de la mano con el avance de las tecnologías de captura de video, la resolución de los mismos aumenta cada vez más.

Sin embargo, la inmensa cantidad de usuarios impone un límite al ancho de banda que se le puede dedicar a cada uno, sobretodo para sitios populares como YouTube que sirven miles de videos en cada instante determinado [\textbf{CITA}], e impone la necesidad de criterios para reducir la cantidad de paquetes que se le transfieren a cada usuario.

Un abordaje común y ampliamente difundido es la compresión de videos, con o sin pérdida de calidad. En términos generales, consiste en que el servidor envíe una versión comprimida del video (posiblemente precomputada de antemano) y que el usuario use su propio poder de cómputo para descomprimirlo y visualizarlo. De este modo se reduce la cantidad de tráfico en la red a costa de un trabajo mayor de CPU de servidores y usuarios, que en general resulta menos costoso.

Los resultados de este trabajo pueden utilizarse como método de compresión con pérdida. Visto de ese modo, una versión \emph{comprimida} de un video es un nuevo video con un subconjunto de los frames del original. El mecanismo de compresión, entonces, resulta muy sencillo de implementar. Para realizar la descompresión se precisa, entonces, generar los frames faltantes a partir de los recibidos. El objetivo de este trabajo es el estudio de distintos métodos para resolver ese problema.

Pero la compresión de videos no es la motivación principal de los métodos estudiados. Para dicho problema existen variados algoritmos que, sin eliminar cuadros completos, representan cada uno en función de los cambios respecto de los anteriores, obteniendo resultados más fieles (dado que no eliminan por completo la información de ningún cuadro) sin un tamaño mucho mayor\cite{wiki_data_compression_video}.

\subsubsection{Reproducción en cámara lenta}
Otra motivación posible y más generalizada resulta de analizar las tecnologías de captura de video. Desde su invención, el principio básico se mantuvo intacto: capturar varias imágenes por segundo y reproducirlas en orden para dar al ojo humano la sensación de movimiento. Un video, entonces, no es más que una secuencia de imagenes (en adelante \emph{frames}) reproducidas a una frecuencia determinada, en general mayor a 12 por segundo (el máximo que el sistema visual humano puede percibir como imágenes separadas\cite{wiki_framerate}). En la época del cine mudo las películas se filmaban con cámaras manuales, lo cual permitía alterar la cantidad de frames por segundo (en adelante \emph{frame-rate}) según la velocidad que se le quisiera dar a la escena: a mayor frame-rate la escena se percibe más lenta y viceversa. Pero al añadirles sonido fue necesario estandarizar el frame-rate, pues el oído humano es mucho más sensible a cambios de frecuencia que el ojo\cite{wiki_framerate}. Desde entonces el estándar ha sido filmar y reproducir a (aproximadamente) 24 cuadros por segundo, tanto películas como demás videos, lo cual se mantuvo prácticamente intacto hasta 2012 con la llegada del Cine en Alta Frecuencia (\emph{HFR} por sus siglas en inglés) de la mano de Peter Jacson en \emph{The Hobbit: An Unexpected Journey}.

A lo largo de la historia y cada vez con mayor frecuencia se han utilizado Cámaras de Alta Velocidad (\emph{HSC}) para generar videos que, reproducidos a 24 \emph{fps}\footnote{frames por segundo, unidad estándar del frame-rate} permitan percibir cosas que el ojo humano o incluso quizás una cámara normal no percibiría. Los usos de los mismos son muy variados, y van desde la biomecánica\footnote{\url{https://www.youtube.com/watch?v=VSzpM8vEAFA}} hasta los eventos deportivos\footnote{\url{https://www.youtube.com/watch?v=O0lCJfFtjCQ}}, pasando incluso por meras curiosidades\footnote{\url{https://www.youtube.com/watch?v=tw3q4_jZv8M}}. Sin embargo los videos resultantes son sumamente pesados por unidad de tiempo, haciéndolos complicados de almacenar, transportar y distribuir. Además, el equipo necesario para realizar las capturas suele ser mucho más costoso que el equipamiento normal. O quizás simplemente no se cuenta con una versión en alta velocidad de un video ya filmado.

Dicho en líneas más generales, es posible que se desee reproducir en cámara lenta un video del cual, por el motivo que fuere, solo se tiene una versión con frame-rate estándar. Una solución es generar computacionalmente los frames faltantes, aprovechando la información existente para crear frames que se acerquen lo más posible a los que hubiese producido una HFC. Lo cual nos lleva nuevamente al objeto de estudio de este trabajo.

\subsubsection{Suavización de video y Morphing}
También es posible que lo que se busque sea generar frames nuevos a partir de un video ya existente pero no con la intención de verlo en cámara lenta sino para que el resultado final sea más ``suave'' o agradable a la vista. Es un proceso común en los videos animados dibujados a mano\footnote{De hecho el primer video animado de la historia, Fantasmagorie de 1908, tiene solo la mitad de sus cuadros realmente dibujados.}, dado que el trabajo extra necesario para dibujar cada frame individualmente difícilmente sea apreciado por el espectador final. Hoy en día se utiliza también en animaciones por computadora, por ejemplo para realizar una trancisión fluida entre dos expresiones de una cara o entre dos estados posibles de un cuerpo 3D.

Un objetivo similar es generar una trancisión entre dos fotos o videos que no necesariamente forman parte de umna misma captura, pero que se quiere integrar en un único y, en lo posible, fluido video. Los usos más comunes del \emph{morphing}, como se le llama, consisten en transformar la cara de una persona en la de otra\footnote{Como se puede ver en este excelente ejemplo: \url{https://www.youtube.com/watch?v=3ZHtL7CirJA}}.

\subsection{Marco teórico}
Nos interesa, entonces, transformar videos computacionalmente para que se perciban más lentamente, que el resultado final se vea ``fluido'' y se acerque lo más posible a lo que se habría capturado usando una Cámara de Alta Velocidad. Lo primero que hace falta es modelar los videos de un modo que nos permita manejarlos usando lenguajes de programación conocidos, sin incluir herramientas de edición complejas que exceden al alcance de este trabajo. Usamos entonces que un video, en su forma ``original'' (sin compresión) es un conjunto ordenado de imágenes, cada una de la cual representa un frame. En consecuencia, el problema consiste en generar nuevas imágenes ``intermedias'' para que, al reproducir el video con el mismo frame-rate, se perciba más lento. A esto \'ultimo lo conoceremos como el efecto de \emph{slowmotion}.

Cada imagen, a su vez, se puede modelar como una matriz de píxeles. Para simplificar el análisis, consideraremos todas las imágenes (y por lo tanto los videos) únicamente en escala de grises\footnote{Numerical representation: \url{https://en.wikipedia.org/wiki/Grayscale}}. De este modo, un píxel se puede representar con entero entre 0 y 255 inclusive (un byte) que denota la cantidad de luz que hay en ese píxel particular (siendo 0 el negro absoluto y 255 el blanco absoluto).

La generación de estas nuevas imágenes intermedias puede hacerse de diversas maneras. Una de ellas, aplicada en este trabajo, implica generarlas píxel por píxel, utilizando la información que nos brindan los píxeles correspondientes de las imágenes cercanas en el tiempo. Más formalmente, para cada píxel $p$ de cada frame $f$ a generar tomamos como información los píxeles que están en la misma posición que $p$ en las imágenes cercanas a $f$ en el tiempo.

Se nos presenta el problema de cómo utilizar esa información para generar un píxel que resulte en un video final con las propiedades deseadas. En este trabajo estudiamos diferentes métodos y los comparamos estableciendo métricas cualitativas y cuantitativas. Pero para introducir el detalle de los métodos hace falta hacer algunas definiciones previas.

\subsubsection{Interpolación}
Dado un conjunto de puntos en $\mathbb{R}^2 (x_0, y_0), \ldots, (x_n, y_n)$ con $x_i \neq x_j$ si $i \neq j$ , decimos que una función $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ interpola dichos puntos si $f(x_i) = y_i$ para todo $i = 0, \ldots, n$. En particular, si nos restringimos a considerar polinomios, se puede demostrar que dados $n + 1$ puntos como los descritos existe un único polinomio $P \in \mathbb{R}[x]$ de grado menor o igual que $n$ tal que los interpola[\cite{wiki_lagrange_polynomial}]. A este polinomio se lo conoce como \emph{Polinomio Interpolador de Lagrange}, y su fórmula esta dada de la siguiente manera:

\[P(x) = \sum_{k = 0}^n \left(y_k \prod_{i \neq k}^n \frac{x - x_i}{x_k - x_i}\right)\]

Sin embargo, los polinomios interpolantes tienen la desventaja de que cuando el $n$ es grande \emph{oscilan} demasiado. Es por esto que en general se utiliza la técnica de \emph{Interpolación segmentada}, que consiste en desarrollar la función interpolante $f$ de a partes tomando subconjuntos de puntos consecutivos, generando el poliniomio interpolante de cada subconjunto y luego ``conectando'' cada uno de estos en el orden adecuado.

Existen diversos tipos de Interpolaci\'on segmentada, entre ellos la lineal, cuadr\'atica y c\'ubica, nombrados según el grado de cada polinomio interpolante. Para la aplicaci\'on del efecto de \emph{slowmotion}, se utilizar\'a la lineal y c\'ubica. A continuaci\'on se dar\'a una breve explicaci\'on de estos dos m\'etodos de interpolaci\'on. 

\subsubsection{Lineal}

El caso m\'as sencillo es la \textbf{Interpolación segmentada lineal}: construimos $S_0, \ldots, S_{n - 1}$ polinomios tal que $S_i$ interpola $x_i$ y $x_{i + 1}$ y definimos

\[
f(x) = 
\left\{
    \begin{array}{ll}
        S_0(x)  & \mbox{si } x \in [x_{0}, x_1] \\
        \hspace{0.3cm}\vdots \\     
        S_{n - 1}(x) & \mbox{si } x \in [x_{n - 1}, x_n]
    \end{array}
\right.
\]

como la función interpolante final. Notar que, por ser cada $S_i$ polinomio interpolante de dos puntos, cada $S_i$ es de grado a lo sumo 1, con lo cual es simplemente una recta.

La interpolación segmetada lineal, no obstante, posee el problema de no resultar ``suave'' geométricamente, es decir, no es derivable en los puntos considerados. Esto, sumado a problemas diferentes que trae la utilización de polinomios cuadráticos, nos motiva a usar polinomios cúbicos, dando lugar a la técnica conocida como \emph{splines}.

\subsubsection{Splines (Interpolaci\'on c\'ubica)}

Al igual que en la Interpolaci\'on lineal, se procede a construir $S_0, \ldots, S_{n - 1}$ polinomios donde cada uno de ellos interpola un segmento equiespaciado sobre $x_i$ y $x_{i + 1}$ ($i = 0, \ldots, n$). La diferencia es que dichos polinomios son de grado 3 y por ende son de la forma: \[ S_i(x) = a_i x^3 + b_i x^2 + c_i x + d_i \]

En resumen, se desea obtener la tupla de coeficientes $(a_i,b_i,c_i,d_i)$ para $i = 0, \ldots, n$. Para ello se utiliza una serie de condiciones que, de cumplirse, mejorarían el problema descrito de la interpolación lineal. Enumeramos estos requisitos, primero, desde una perspectiva m\'as conceptual y no tan formal:

\begin{enumerate}
	\item Los polinomios $S_i$ deben pasar por los conjuntos de puntos $(x_i,y_i)$ que se establecieron como datos iniciales. Es decir, asegurar que la funci\'on resultante sea continua e interpole a los puntos originales.
	\item Se debe mantener tambi\'en la continuidad en las derivadas primeras y segundas. En otras palabras, por cada par $S_i, S_{i+1}$ con $i = 0, \ldots, n-2$ se debe cumplir la igualdad de la derivada primera y segunda de dichos polinomios en el punto en que se conectan ($x_{i+1}$).
	\item Para la \'ultima restricci\'on se consideran dos opciones:
		\begin{enumerate}
			\item La derivada segunda en los bordes de la funci\'on debe ser nula cuando se evalua en el $x_0$ y $x_n$, respectivamente. Se la define como \textit{Spline natural}.
			\item La derivada primera en los bordes coinciden con el de la funci\'on original que se est\'a aproximando en el punto $x_0$ y $x+n$, respectivamete. Esto implica que se necesita de cierta informaci\'on extra sobre la funci\'on a interpolar. Por esta raz\'on, se la conoce como \textit{Spline sujeto a la funci\'on interpolada}.  
		\end{enumerate}
\end{enumerate}

Formalmente, todo esto se expresa como

\begin{enumerate}
\item $S_i(x_i) = y_i$ para todo $i = 0, \ldots, n-1$, y $S_{n-1}(x_n)=y_n$
\item $S_i(x_{i + 1}) = S_{i+1}(x_{i + 1})$ para todo $i = 0, \ldots, n - 2$
\item $S_i'(x_{i + 1}) = S_{i+1}'(x_{i + 1})$ para todo $i = 0, \ldots, n - 2$
\item $S_i''(x_{i + 1}) = S_{i+1}''(x_{i + 1})$ para todo $i = 0, \ldots, n - 2$
\item Se cumple que
\begin{enumerate}
\item $S''(x_0) = S''(x_n) = 0$ (spline natural)
\item $S'(x_0) = f'(x_0)$ y $S'(x_n) = f'(x_n)$ (spline sujeto)
\end{enumerate} 
\end{enumerate}

Y definimos entonces al \emph{spline} como el conjunto de todas las funciones cúbicas $S_i$:
$$
S(x) = 
\left\{
    \begin{array}{ll}
        S_0(x)  & \mbox{si } x \in [x_{0}, x_1] \\
        \hspace{0.3cm}\vdots \\     
        S_{n - 1}(x) & \mbox{si } x \in [x_{n - 1}, x_n]
    \end{array}
\right.
$$


A pesar de su mejora en ciertos aspectos, como la suavidad del \emph{spline}, la cantidad de c\'alculos a realizar es mayor, lo cual nos lleva a un problema en el \'ambito computacional.

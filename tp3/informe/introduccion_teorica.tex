%!TEX root = informe.tex
\IEEEPARstart{E}{N} el siguiente trabajo se aborda el desafío de aumentar algorítmicamente la cantidad de frames de un video de manera que el resultado se asemeje al video original. En otras palabras, el objetivo es, a partir de un video, generar otro con mayor cantidad de frames, de modo tal que coincidan en aquellos frames presentes en el video original y los frames generados se \emph{ajusten} a estos, apuntando idealmente a que el ojo humano no perciba el agregado artificial.

En esta introducción presentaremos una lista no exhaustiva de las diversas situaciones que motivan la resolución de dicho problema y daremos un marco teórico a los métodos propuestos para su solución.

\subsection{La motivación}
\subsubsection{Compresión de video}
El aumento exponencial de internet ha dado lugar, entre otras cosas\cite{TP2}, a la mejora de la infraestructura utilizada, lo que en particular repercutió en un aumento generalizado de las velocidades de conexión y del ancho de banda de las mismas. Esto promovió su utilización para compartir contenido cada vez más pesado, en particular videos de todo tipo, desde caseros a profesionales. Además, de la mano con el avance de las tecnologías de captura de video, la resolución de los mismos aumenta cada vez más.

Sin embargo, la inmensa cantidad de usuarios impone un límite al ancho de banda que se le puede dedicar a cada uno, sobretodo para sitios populares como YouTube que sirven miles de videos en cada instante determinado [\textbf{CITA}], e impone la necesidad de criterios para reducir la cantidad de paquetes que se le transfieren a cada usuario.

Un abordaje común y ampliamente difundido es la compresión de videos, con o sin pérdida de calidad. En términos generales, consiste en que el servidor envíe una versión comprimida del video (posiblemente precomputada de antemano) y que el usuario use su propio poder de cómputo para descomprimirlo y visualizarlo. De este modo se reduce la cantidad de tráfico en la red a costa de un trabajo mayor de CPU de servidores y usuarios, que en general resulta menos costoso.

Los resultados de este trabajo pueden utilizarse como método de compresión con pérdida. Visto de ese modo, una versión \emph{comprimida} de un video es un nuevo video con un subconjunto de los frames del original. El mecanismo de compresión, entonces, resulta muy sencillo de implementar. Para realizar la descompresión se precisa, entonces, generar los frames faltantes a partir de los recibidos. El objetivo de este trabajo es el estudio de distintos métodos para resolver ese problema.

Pero la compresión de videos no es la motivación principal de los métodos estudiados. Para dicho problema existen variados algoritmos que, sin eliminar cuadros completos, representan cada uno en función de los cambios respecto de los anteriores, obteniendo resultados más fieles (dado que no eliminan por completo la información de ningún cuadro) sin un tamaño mucho mayor\cite{wiki_data_compression_video}.

\subsubsection{Reproducción en cámara lenta}
Otra motivación posible y más generalizada resulta de analizar las tecnologías de captura de video. Desde su invención, el principio básico se mantuvo intacto: capturar varias imágenes por segundo y reproducirlas en orden para dar al ojo humano la sensación de movimiento. Un video, entonces, no es más que una secuencia de imagenes (en adelante \emph{frames}) reproducidas a una frecuencia determinada, en general mayor a 12 por segundo (el máximo que el sistema visual humano puede percibir como imágenes separadas\cite{wiki_framerate}). En la época del cine mudo las películas se filmaban con cámaras manuales, lo cual permitía alterar la cantidad de frames por segundo (en adelante \emph{frame-rate}) según la velocidad que se le quisiera dar a la escena: a mayor frame-rate la escena se percibe más lenta y viceversa. Pero al añadirles sonido fue necesario estandarizar el frame-rate, pues el oído humano es mucho más sensible a cambios de frecuencia que el ojo\cite{wiki_framerate}. Desde entonces el estándar ha sido filmar y reproducir a (aproximadamente) 24 cuadros por segundo, tanto películas como demás videos, lo cual se mantuvo prácticamente intacto hasta 2012 con la llegada del Cine en Alta Frecuencia (\emph{HFR} por sus siglas en inglés) de la mano de Peter Jacson en \emph{The Hobbit: An Unexpected Journey}.

A lo largo de la historia y cada vez con mayor frecuencia se han utilizado Cámaras de Alta Velocidad (\emph{HSC}) para generar videos que, reproducidos a 24 \emph{fps}\footnote{frames por segundo, unidad estándar del frame-rate} permitan percibir cosas que el ojo humano o incluso quizás una cámara normal no percibiría. Los usos de los mismos son muy variados, y van desde la biomecánica\footnote{\url{https://www.youtube.com/watch?v=VSzpM8vEAFA}} hasta los eventos deportivos\footnote{\url{https://www.youtube.com/watch?v=O0lCJfFtjCQ}}, pasando incluso por meras curiosidades\footnote{\url{https://www.youtube.com/watch?v=tw3q4_jZv8M}}. Sin embargo los videos resultantes son sumamente pesados por unidad de tiempo, haciéndolos complicados de almacenar, transportar y distribuir. Además, el equipo necesario para realizar las capturas suele ser mucho más costoso que el equipamiento normal. O quizás simplemente no se cuenta con una versión en alta velocidad de un video ya filmado.

Dicho en líneas más generales, es posible que se desee reproducir en cámara lenta un video del cual, por el motivo que fuere, solo se tiene una versión con frame-rate estándar. Una solución es generar computacionalmente los frames faltantes, aprovechando la información existente para crear frames que se acerquen lo más posible a los que hubiese producido una HFC. Lo cual nos lleva nuevamente al objeto de estudio de este trabajo.

\subsubsection{Suavización de video y Morphing}
También es posible que lo que se busque sea generar frames nuevos a partir de un video ya existente pero no con la intención de verlo en cámara lenta sino para que el resultado final sea más ``suave'' o agradable a la vista. Es un proceso común en los videos animados dibujados a mano\footnote{De hecho el primer video animado de la historia, Fantasmagorie de 1908, tiene solo la mitad de sus cuadros realmente dibujados.}, dado que el trabajo extra necesario para dibujar cada frame individualmente difícilmente sea apreciado por el espectador final. Hoy en día se utiliza también en animaciones por computadora, por ejemplo para realizar una trancisión fluida entre dos expresiones de una cara o entre dos estados posibles de un cuerpo 3D.

Un objetivo similar es generar una trancisión entre dos fotos o videos que no necesariamente forman parte de umna misma captura, pero que se quiere integrar en un único y, en lo posible, fluido video. Los usos más comunes del \emph{morphing}, como se le llama, consisten en transformar la cara de una persona en la de otra\footnote{Como se puede ver en este excelente ejemplo: \url{https://www.youtube.com/watch?v=3ZHtL7CirJA}}.

\subsection{Marco teórico}
Nos interesa, entonces, transformar videos computacionalmente para que se perciban más lentamente, que el resultado final se vea ``fluido'' y se acerque lo más posible a lo que se habría capturado usando una Cámara de Alta Velocidad. Lo primero que hace falta es modelar los videos de un modo que nos permita manejarlos usando lenguajes de programación conocidos, sin incluir herramientas de edición complejas que exceden al alcance de este trabajo. Usamos entonces que un video, en su forma ``original'' (sin compresión) es un conjunto ordenado de imágenes, cada una de la cual representa un frame. El problema entonces consiste en generar nuevas imágenes ``intermedias'' para que, al reproducir el video con el mismo frame-rate, se perciba más lento.

Cada imagen, a su vez, se puede modelar como una matriz de píxeles. Para simplificar el análisis, consideraremos todas las imágenes (y por lo tanto los videos) únicamente en escala de grises\footnote{Numerical representation: \url{https://en.wikipedia.org/wiki/Grayscale}}. De este modo, un píxel se puede representar con entero entre 0 y 255 inclusive (un byte) que denota la cantidad de luz que hay en ese píxel particular (siendo 0 el negro absoluto y 255 el blanco absoluto).

La generación de estas nuevas imágenes intermedias puede hacerse de diversas maneras. Una de ellas, utilizada en este trabajo, implica generarlas píxel por píxel, utilizando la información que nos brindan los píxeles correspondientes de las imágenes cercanas en el tiempo. Más formalmente, para cada píxel $p$ de cada frame $f$ a generar tomamos como información los píxeles que están en la misma posición que $p$ en las imágenes cercanas a $f$ en el tiempo.

Se nos presenta entonces el problema de cómo utilizar esa información para generar un píxel que resulte en un video final con las propiedades deseadas. En este trabajo estudiamos diferentes métodos y los comparamos estableciendo métricas cualitativas y cuantitativas. Pero para introducir el detalle de los métodos hace falta hacer algunas definiciones previas.

\subsubsection{Interpolación}
Dado un conjunto de puntos en $\mathbb{R}^2 (x_0, y_0), \ldots, (x_n, y_n)$ con $x_i \neq x_j$ si $i \neq j$ decimos que una función $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ interpola dichos puntos si $f(x_i) = y_i$ para todo $i = 0 \ldots n$. En particular, si nos restringimos a considerar polinomios, se puede demostrar que dados $n + 1$ puntos como los descritos existe un único polinomio $P \in \mathbb{R}[x]$ de grado menor o igual que $n$ tal que los interpola[\cite{wiki_lagrange_polynomial}]. A este polinomio se lo conoce como \emph{Polinomio Interpolador de Lagrange}, y su fórmula es 

\[P(x) = \sum_{k = 0}^n \left(y_k \prod_{i \neq k}^n \frac{x - x_i}{x_k - x_i}\right)\]

Sin embargo, los polinomios interpoladores tienen la desventaja de que cuando el $n$ es grande \emph{oscilan} demasiado. Es por esto que en general se utiliza la técnica de \emph{Interpolación segmentada}, que consiste en generar la función interpolante $f$ de a partes tomando subconjuntos de puntos consecutivos, generando el poliniomio interpolante de cada subconjunto y luego ``conectando'' todos.

\subsubsection{Lineal}

El caso más sencillo es la Interpolación segmentada lineal: construimos $S_0, \cdots, S_{n - 1}$ polinomios tal que $S_i$ interpola $x_i$ y $x_{i + 1}$ y definimos

\[
f(x) = 
\left\{
    \begin{array}{ll}
        S_0(x)  & \mbox{si } x \in [x_{0}, x_1] \\
        \hspace{0.3cm}\vdots \\     
        S_{n - 1}(x) & \mbox{si } x \in [x_{n - 1}, x_n]
    \end{array}
\right.
\]

la función interpolante final. Notar que, por ser cada $S_i$ polinomio interpolante de dos puntos, cada $S_i$ es de grado a lo sumo 1, con lo cual es simplemente una recta.

La interpolación segmetada lineal, sin embargo, tiene el problema de no resultar ``suave'' geométricamente, es decir, no es derivable en los puntos considerados. Esto, sumado a problemas diferentes que trae la utilización de polinomios cuadráticos, nos motiva a usar polinomios cúbicos, dando lugar a la técnica conocida como \emph{splines}.

\subsubsection{Splines}

\subsection{Los m\'etodos propuestos}

Finalizada la enumeraci\'on de ciertos rubros que motiven la investigaci\'on sobre el tema, nos desviaremos al marco te\'orico que se nos presenta. A continuaci\'on, daremos una breve explicaci\'on de cada herramienta que encaminar\'a a las posible soluciones al problema de construir, a partir de un video en tiempo real, una secuencia de im\'agenes generadas de forma artificial que explaye la sensaci\'on de que el video original ha sido alentizado. A esto \'ultimo lo definimos como el efecto de $slowmotion$.

\subsubsection{Cuadro m\'as cercano}

Este m\'etodo se basa en una idea de car\'acter simplista, pero comprende de una intuici\'on que puede resultar de utilidad para ciertos tipos de videos, como por ejemplo, la filmaci\'on de un objeto inm\'ovil.

Se extrae cada cuadro/frame en el orden en que el video los reproduce y tomando de a pares, se le adiciona una cierta cantidad de frames de por medio. No hay un n\'umero exacto que represente esta cantidad, por lo que se lo interpreta como par\'ametro de experimentaci\'on. Sin embargo, nos resta como inc\'ognita, el procedimiento por el cual se obtiene dichos cuadros. Esto \'ultimo es lo que caracterizar\'a al m\'etodo en cuesti\'on.

Nos abstraemos por un momento de la totalidad de frames que compone una grabaci\'on para analizar en detalle el conjunto de im\'agenes resultantes entre cada par de cuadros de la repoducci\'on original. Asumimos que se decidi\'o la cantidad de frames a realizar. Para un mejor entendimiento, llamaremos a estos cuadros como \textit{frames artificiales}. Por otro lado, el par de frames provenientes del video original, se lo conocer\'an como \textit{frames originales}.

Como lo indica el sub-t\'itulo de la secci\'on, mediante un algoritmo que muestra la posici\'on del frame artificial entre los dos frames originales, determinamos a qu\'e distancia se encuentra de ambos extremos. Recordemos que se ingresaron $n$ cuadros entre medio de los originales. Una vez realizado el paso de b\'usqueda, se decide copiar la im\'agen del extremo m\'as cercano al frame artificial que se est\'a evaluando. 

De esta manera, habr\'a al menos (despreciando decimales) $n/2$  frames cuya im\'agen ser\'a id\'entica a la de alguno de los dos frames originales. En caso que se decida agregar una cantidad impar, se opta por fragmentar en dos partes de $n/2$ y $n/2+1$ cuadros. En la partici\'on de mayor peso
, es el usuario quien selecciona qu\'e extremo escoger de los originales. En la siguiente figura, nos encontramos con un ejemplo consico de lo explicado: 

( Ejemplo gra\'fico o dejar eso para el desarrollo )

( Breve explicaci\'on del ejemplo )

Volviendo al an\'alisis del video en su mera totalidad, se repite el anterior procedimiento en cada par de frames en el orden concebido por la secuencia del video. De tal forma, se obtienen los frames artificiales, consiguiendo una nueva filmaci\'on con el efecto de $slowmotion$ que este m\'etodo propone. 

( Alg\'un comentario final )

\subsubsection{Interpolaci\'on lineal}

Semejante al \textit{cuadro m\'as cercano}, en el sentido que comparten la ideolog\'ia de trabajar c\'iclicamente con cada par de frames para eventualmente, obtener el video deseado con su respectivo efecto. No obstante, contaremos lo particular y caracter\'istico de este m\'etodo, que puede propocionar ciertas mejoras en el movimiento de objetos durante su filmaci\'on.

Por un lado, no posee la misma intuici\'on que su antecesora, donde la im\'agen de cada frame artificial se basa en copiar alguno de los dos cuadros originales en evaluaci\'on. En cambio, se busca utilizar fundamentos matem\'aticos que ayuden a \textit{predecir y reflejar} lo sucedido entre cada par de frames del video original. 

Nuevamente, nos enfocamos en analizar el algoritmo propuesto para la creaci\'on de los $n$ frames artificiales que se desean adherir entre cada conjunto de pares. En primer lugar, debemos pensar a cada frame como una matriz de $m$ $x$ $n$ p\'ixeles (dependiendo la resoluci\'on en que se dispone el video), siendo $m$ el largo del cuadro y $n$ el ancho. En segundo lugar, el procedimiento destina a generar un polinomio de grado uno \footnote{ Tambi\'en definida como funci\'on lineal; \url{https://es.wikipedia.org/wiki/Lineal}.} entre ese par de frames originales. Aunque, ¿de qu\'e forma inventaremos dichos polinomios? Para ello, introducimos algunos conceptos que resolver\'an esta inc\'ognita.

Contamos previamente acerca de la idealizaci\'on de tales cuadros como matrices compuestas por p\'ixeles. Sin embargo, en ning\'un momento se aclar\'o del valor num\'erico que posee cada posici\'on. Consideramos un rango en el conjunto de n\'umeros enteros del $0$ al $255$, inclusive. Esta \'ultima se la conoce como \textbf{escala de grises en 8 bits} \footnote{Numerical representation : \url{https://en.wikipedia.org/wiki/Grayscale}}, y su importancia revoca en que cada p\'ixel de los frames artificiales adquirir\'a un valor num\'erico dentro ese rango.

Dicho esto, el m\'etodo se centra en crear un polinomio interpolador por cada posici\'on del frame cuyos puntos interpolados \textbf{(creo que no es puntos interpolados, pero no se me ocurre el verdadero)} resultan ser los valores de dicha ubicaci\'on en el par de frames originales que se est\'a trabajando. Por ende, tendremos por cada par de cuadros reales, $m$ $x$ $n$ polinomios de grado uno. De lo anterior, nace una nueva duda : ¿C\'omo esto resuelve nuestro problema de crear m\'utiples frames artificiales?

El hecho esta en que ahora conocemos los valores intermedios entre los dos cuadros originales y en consecuencia, podemos particionar ese dominio en $p$ partes ($p$ siendo la cantidad de frames que se adiciona en cada par) y finalmente, evaluar el polinomio en dicho borde de cada fragmento. Como observaci\'on, este paso lo tendremos que aplicar para cada posici\'on de la im\'agen.

De misma forma, se realiza la tarea sobre cada par agrupado en el orden indicado con lo que eventualmente, el m\'etodo en cuesti\'on concluye con su labor, dejando el efecto de $slowmotion$ que la misma ofrece.

( Cosas para agregar : imagenes o ejemplo sencillo. No se si explicar polinomio interpolado aca o en el desarrollo. Etc. Rta de L: va antes, lo pongo en una sección anterior. Va a haber que reorganizar un poco esto porque nos estamos repitiendo.) 